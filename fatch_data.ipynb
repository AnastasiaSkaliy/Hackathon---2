{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjlXrIJDzduG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "def save_data(data, file_name):\n",
        "\n",
        "  with open(f'{file_name}.json', 'w', encoding='utf-8') as f:\n",
        "      json.dump(data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "def fetch_data(data_type, total_batch = 30):\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:121.0) Gecko/20100101 Firefox/121.0'\n",
        "    }\n",
        "    batch_size = 100\n",
        "    offset = 1\n",
        "    data = []\n",
        "    for i in range(1, total_batch):\n",
        "        url = f\"https://www.colourlovers.com/api/{data_type}/?format=json&resultOffset={offset}&numResults=100\"\n",
        "        offset = offset + batch_size\n",
        "        response = requests.get(url, headers=headers)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            batch = response.json()\n",
        "            print(f'batch number {i} with #{len(batch)} records fetched')\n",
        "            data = data + batch\n",
        "            print(f'total data size is {len(data)}')\n",
        "\n",
        "        else:\n",
        "            print(\"Failed to retrieve data. Status code:\", response.status_code)\n",
        "    return data"
      ],
      "metadata": {
        "id": "xDW5v2TZNUP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = fetch_data('palettes/top')\n",
        "id_set = set()\n",
        "for row in data:\n",
        "  id_set.add(row['id'])\n",
        "save_data(data, 'palettes_top')\n",
        "\n",
        "print(f'total unique id {len(id_set)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJDvPFiF1dsE",
        "outputId": "5fc65413-cc7e-4cdd-80e3-e3c9c6d3b45c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch number 1 with #100 records fetched\n",
            "total data size is 100\n",
            "batch number 2 with #100 records fetched\n",
            "total data size is 200\n",
            "batch number 3 with #100 records fetched\n",
            "total data size is 300\n",
            "batch number 4 with #100 records fetched\n",
            "total data size is 400\n",
            "batch number 5 with #100 records fetched\n",
            "total data size is 500\n",
            "batch number 6 with #100 records fetched\n",
            "total data size is 600\n",
            "batch number 7 with #100 records fetched\n",
            "total data size is 700\n",
            "batch number 8 with #100 records fetched\n",
            "total data size is 800\n",
            "batch number 9 with #100 records fetched\n",
            "total data size is 900\n",
            "batch number 10 with #99 records fetched\n",
            "total data size is 999\n",
            "batch number 11 with #100 records fetched\n",
            "total data size is 1099\n",
            "batch number 12 with #100 records fetched\n",
            "total data size is 1199\n",
            "batch number 13 with #100 records fetched\n",
            "total data size is 1299\n",
            "batch number 14 with #100 records fetched\n",
            "total data size is 1399\n",
            "batch number 15 with #100 records fetched\n",
            "total data size is 1499\n",
            "batch number 16 with #100 records fetched\n",
            "total data size is 1599\n",
            "batch number 17 with #100 records fetched\n",
            "total data size is 1699\n",
            "batch number 18 with #100 records fetched\n",
            "total data size is 1799\n",
            "batch number 19 with #100 records fetched\n",
            "total data size is 1899\n",
            "batch number 20 with #100 records fetched\n",
            "total data size is 1999\n",
            "batch number 21 with #100 records fetched\n",
            "total data size is 2099\n",
            "batch number 22 with #100 records fetched\n",
            "total data size is 2199\n",
            "batch number 23 with #100 records fetched\n",
            "total data size is 2299\n",
            "batch number 24 with #100 records fetched\n",
            "total data size is 2399\n",
            "batch number 25 with #100 records fetched\n",
            "total data size is 2499\n",
            "batch number 26 with #100 records fetched\n",
            "total data size is 2599\n",
            "batch number 27 with #100 records fetched\n",
            "total data size is 2699\n",
            "batch number 28 with #100 records fetched\n",
            "total data size is 2799\n",
            "batch number 29 with #100 records fetched\n",
            "total data size is 2899\n",
            "total unique id 999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = fetch_data('colors/top', 100)\n",
        "id_set = set()\n",
        "for row in data:\n",
        "  id_set.add(row['id'])\n",
        "\n",
        "save_data(data, 'colors_top')\n",
        "\n",
        "print(f'total unique id {len(id_set)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kGd0H9ItbYx",
        "outputId": "0a1791bc-11c4-44ae-8f97-ebd1c542c966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch number 1 with #100 records fetched\n",
            "total data size is 100\n",
            "batch number 2 with #100 records fetched\n",
            "total data size is 200\n",
            "batch number 3 with #100 records fetched\n",
            "total data size is 300\n",
            "batch number 4 with #100 records fetched\n",
            "total data size is 400\n",
            "batch number 5 with #100 records fetched\n",
            "total data size is 500\n",
            "batch number 6 with #100 records fetched\n",
            "total data size is 600\n",
            "batch number 7 with #100 records fetched\n",
            "total data size is 700\n",
            "batch number 8 with #100 records fetched\n",
            "total data size is 800\n",
            "batch number 9 with #100 records fetched\n",
            "total data size is 900\n",
            "batch number 10 with #100 records fetched\n",
            "total data size is 1000\n",
            "batch number 11 with #100 records fetched\n",
            "total data size is 1100\n",
            "batch number 12 with #100 records fetched\n",
            "total data size is 1200\n",
            "batch number 13 with #100 records fetched\n",
            "total data size is 1300\n",
            "batch number 14 with #100 records fetched\n",
            "total data size is 1400\n",
            "batch number 15 with #100 records fetched\n",
            "total data size is 1500\n",
            "batch number 16 with #100 records fetched\n",
            "total data size is 1600\n",
            "batch number 17 with #100 records fetched\n",
            "total data size is 1700\n",
            "batch number 18 with #100 records fetched\n",
            "total data size is 1800\n",
            "batch number 19 with #100 records fetched\n",
            "total data size is 1900\n",
            "batch number 20 with #100 records fetched\n",
            "total data size is 2000\n",
            "batch number 21 with #100 records fetched\n",
            "total data size is 2100\n",
            "batch number 22 with #100 records fetched\n",
            "total data size is 2200\n",
            "batch number 23 with #100 records fetched\n",
            "total data size is 2300\n",
            "batch number 24 with #100 records fetched\n",
            "total data size is 2400\n",
            "batch number 25 with #100 records fetched\n",
            "total data size is 2500\n",
            "batch number 26 with #100 records fetched\n",
            "total data size is 2600\n",
            "batch number 27 with #100 records fetched\n",
            "total data size is 2700\n",
            "batch number 28 with #100 records fetched\n",
            "total data size is 2800\n",
            "batch number 29 with #100 records fetched\n",
            "total data size is 2900\n",
            "batch number 30 with #100 records fetched\n",
            "total data size is 3000\n",
            "batch number 31 with #100 records fetched\n",
            "total data size is 3100\n",
            "batch number 32 with #100 records fetched\n",
            "total data size is 3200\n",
            "batch number 33 with #100 records fetched\n",
            "total data size is 3300\n",
            "batch number 34 with #100 records fetched\n",
            "total data size is 3400\n",
            "batch number 35 with #100 records fetched\n",
            "total data size is 3500\n",
            "batch number 36 with #100 records fetched\n",
            "total data size is 3600\n",
            "batch number 37 with #100 records fetched\n",
            "total data size is 3700\n",
            "batch number 38 with #100 records fetched\n",
            "total data size is 3800\n",
            "batch number 39 with #100 records fetched\n",
            "total data size is 3900\n",
            "batch number 40 with #100 records fetched\n",
            "total data size is 4000\n",
            "batch number 41 with #100 records fetched\n",
            "total data size is 4100\n",
            "batch number 42 with #100 records fetched\n",
            "total data size is 4200\n",
            "batch number 43 with #100 records fetched\n",
            "total data size is 4300\n",
            "batch number 44 with #100 records fetched\n",
            "total data size is 4400\n",
            "batch number 45 with #100 records fetched\n",
            "total data size is 4500\n",
            "batch number 46 with #100 records fetched\n",
            "total data size is 4600\n",
            "batch number 47 with #100 records fetched\n",
            "total data size is 4700\n",
            "batch number 48 with #100 records fetched\n",
            "total data size is 4800\n",
            "batch number 49 with #100 records fetched\n",
            "total data size is 4900\n",
            "batch number 50 with #100 records fetched\n",
            "total data size is 5000\n",
            "batch number 51 with #100 records fetched\n",
            "total data size is 5100\n",
            "batch number 52 with #100 records fetched\n",
            "total data size is 5200\n",
            "batch number 53 with #100 records fetched\n",
            "total data size is 5300\n",
            "batch number 54 with #100 records fetched\n",
            "total data size is 5400\n",
            "batch number 55 with #100 records fetched\n",
            "total data size is 5500\n",
            "batch number 56 with #100 records fetched\n",
            "total data size is 5600\n",
            "batch number 57 with #100 records fetched\n",
            "total data size is 5700\n",
            "batch number 58 with #100 records fetched\n",
            "total data size is 5800\n",
            "batch number 59 with #100 records fetched\n",
            "total data size is 5900\n",
            "batch number 60 with #100 records fetched\n",
            "total data size is 6000\n",
            "batch number 61 with #100 records fetched\n",
            "total data size is 6100\n",
            "batch number 62 with #100 records fetched\n",
            "total data size is 6200\n",
            "batch number 63 with #100 records fetched\n",
            "total data size is 6300\n",
            "batch number 64 with #100 records fetched\n",
            "total data size is 6400\n",
            "batch number 65 with #100 records fetched\n",
            "total data size is 6500\n",
            "batch number 66 with #100 records fetched\n",
            "total data size is 6600\n",
            "batch number 67 with #100 records fetched\n",
            "total data size is 6700\n",
            "batch number 68 with #100 records fetched\n",
            "total data size is 6800\n",
            "batch number 69 with #100 records fetched\n",
            "total data size is 6900\n",
            "batch number 70 with #100 records fetched\n",
            "total data size is 7000\n",
            "batch number 71 with #100 records fetched\n",
            "total data size is 7100\n",
            "batch number 72 with #100 records fetched\n",
            "total data size is 7200\n",
            "batch number 73 with #100 records fetched\n",
            "total data size is 7300\n",
            "batch number 74 with #100 records fetched\n",
            "total data size is 7400\n",
            "batch number 75 with #100 records fetched\n",
            "total data size is 7500\n",
            "batch number 76 with #100 records fetched\n",
            "total data size is 7600\n",
            "batch number 77 with #100 records fetched\n",
            "total data size is 7700\n",
            "batch number 78 with #100 records fetched\n",
            "total data size is 7800\n",
            "batch number 79 with #100 records fetched\n",
            "total data size is 7900\n",
            "batch number 80 with #100 records fetched\n",
            "total data size is 8000\n",
            "batch number 81 with #100 records fetched\n",
            "total data size is 8100\n",
            "batch number 82 with #100 records fetched\n",
            "total data size is 8200\n",
            "batch number 83 with #100 records fetched\n",
            "total data size is 8300\n",
            "batch number 84 with #100 records fetched\n",
            "total data size is 8400\n",
            "batch number 85 with #100 records fetched\n",
            "total data size is 8500\n",
            "batch number 86 with #100 records fetched\n",
            "total data size is 8600\n",
            "batch number 87 with #100 records fetched\n",
            "total data size is 8700\n",
            "batch number 88 with #100 records fetched\n",
            "total data size is 8800\n",
            "batch number 89 with #100 records fetched\n",
            "total data size is 8900\n",
            "batch number 90 with #100 records fetched\n",
            "total data size is 9000\n",
            "batch number 91 with #100 records fetched\n",
            "total data size is 9100\n",
            "batch number 92 with #100 records fetched\n",
            "total data size is 9200\n",
            "batch number 93 with #100 records fetched\n",
            "total data size is 9300\n",
            "batch number 94 with #100 records fetched\n",
            "total data size is 9400\n",
            "batch number 95 with #100 records fetched\n",
            "total data size is 9500\n",
            "batch number 96 with #100 records fetched\n",
            "total data size is 9600\n",
            "batch number 97 with #100 records fetched\n",
            "total data size is 9700\n",
            "batch number 98 with #100 records fetched\n",
            "total data size is 9800\n",
            "batch number 99 with #100 records fetched\n",
            "total data size is 9900\n",
            "total unique id 9900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = fetch_data('patterns')\n",
        "id_set = set()\n",
        "for row in data:\n",
        "  id_set.add(row['id'])\n",
        "save_data(data, 'patterns')\n",
        "print(f'total unique id {len(id_set)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFyh2JUk3hae",
        "outputId": "b595167a-b734-4e50-9691-948ef22f9e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch number 1 with #100 records fetched\n",
            "total data size is 100\n",
            "batch number 2 with #100 records fetched\n",
            "total data size is 200\n",
            "batch number 3 with #100 records fetched\n",
            "total data size is 300\n",
            "batch number 4 with #100 records fetched\n",
            "total data size is 400\n",
            "batch number 5 with #100 records fetched\n",
            "total data size is 500\n",
            "batch number 6 with #100 records fetched\n",
            "total data size is 600\n",
            "batch number 7 with #100 records fetched\n",
            "total data size is 700\n",
            "batch number 8 with #100 records fetched\n",
            "total data size is 800\n",
            "batch number 9 with #100 records fetched\n",
            "total data size is 900\n",
            "batch number 10 with #99 records fetched\n",
            "total data size is 999\n",
            "batch number 11 with #100 records fetched\n",
            "total data size is 1099\n",
            "batch number 12 with #100 records fetched\n",
            "total data size is 1199\n",
            "batch number 13 with #100 records fetched\n",
            "total data size is 1299\n",
            "batch number 14 with #100 records fetched\n",
            "total data size is 1399\n",
            "batch number 15 with #100 records fetched\n",
            "total data size is 1499\n",
            "batch number 16 with #100 records fetched\n",
            "total data size is 1599\n",
            "batch number 17 with #100 records fetched\n",
            "total data size is 1699\n",
            "batch number 18 with #100 records fetched\n",
            "total data size is 1799\n",
            "batch number 19 with #100 records fetched\n",
            "total data size is 1899\n",
            "batch number 20 with #100 records fetched\n",
            "total data size is 1999\n",
            "batch number 21 with #100 records fetched\n",
            "total data size is 2099\n",
            "batch number 22 with #100 records fetched\n",
            "total data size is 2199\n",
            "batch number 23 with #100 records fetched\n",
            "total data size is 2299\n",
            "batch number 24 with #100 records fetched\n",
            "total data size is 2399\n",
            "batch number 25 with #100 records fetched\n",
            "total data size is 2499\n",
            "batch number 26 with #100 records fetched\n",
            "total data size is 2599\n",
            "batch number 27 with #100 records fetched\n",
            "total data size is 2699\n",
            "batch number 28 with #100 records fetched\n",
            "total data size is 2799\n",
            "batch number 29 with #100 records fetched\n",
            "total data size is 2899\n",
            "total unique id 999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = fetch_data('lovers/top')\n",
        "id_set = set()\n",
        "for row in data:\n",
        "  id_set.add(row['userName'])\n",
        "save_data(data, 'lovers_top')\n",
        "print(f'total unique id {len(id_set)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIv_A3933rjS",
        "outputId": "7312aa9b-680a-4f56-de1b-f2fac70190b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch number 1 with #100 records fetched\n",
            "total data size is 100\n",
            "batch number 2 with #100 records fetched\n",
            "total data size is 200\n",
            "batch number 3 with #100 records fetched\n",
            "total data size is 300\n",
            "batch number 4 with #100 records fetched\n",
            "total data size is 400\n",
            "batch number 5 with #100 records fetched\n",
            "total data size is 500\n",
            "batch number 6 with #100 records fetched\n",
            "total data size is 600\n",
            "batch number 7 with #100 records fetched\n",
            "total data size is 700\n",
            "batch number 8 with #100 records fetched\n",
            "total data size is 800\n",
            "batch number 9 with #100 records fetched\n",
            "total data size is 900\n",
            "batch number 10 with #100 records fetched\n",
            "total data size is 1000\n",
            "batch number 11 with #100 records fetched\n",
            "total data size is 1100\n",
            "batch number 12 with #100 records fetched\n",
            "total data size is 1200\n",
            "batch number 13 with #100 records fetched\n",
            "total data size is 1300\n",
            "batch number 14 with #100 records fetched\n",
            "total data size is 1400\n",
            "batch number 15 with #100 records fetched\n",
            "total data size is 1500\n",
            "batch number 16 with #100 records fetched\n",
            "total data size is 1600\n",
            "batch number 17 with #100 records fetched\n",
            "total data size is 1700\n",
            "batch number 18 with #100 records fetched\n",
            "total data size is 1800\n",
            "batch number 19 with #100 records fetched\n",
            "total data size is 1900\n",
            "batch number 20 with #100 records fetched\n",
            "total data size is 2000\n",
            "batch number 21 with #100 records fetched\n",
            "total data size is 2100\n",
            "batch number 22 with #100 records fetched\n",
            "total data size is 2200\n",
            "batch number 23 with #100 records fetched\n",
            "total data size is 2300\n",
            "batch number 24 with #100 records fetched\n",
            "total data size is 2400\n",
            "batch number 25 with #100 records fetched\n",
            "total data size is 2500\n",
            "batch number 26 with #100 records fetched\n",
            "total data size is 2600\n",
            "batch number 27 with #100 records fetched\n",
            "total data size is 2700\n",
            "batch number 28 with #100 records fetched\n",
            "total data size is 2800\n",
            "batch number 29 with #100 records fetched\n",
            "total data size is 2900\n",
            "total unique id 2900\n"
          ]
        }
      ]
    }
  ]
}